{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BONN_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32rBKHoLzKKy",
        "colab_type": "text"
      },
      "source": [
        "# Seizure Predicition Procedure\n",
        "1.   Preprocessing for the used dataset\n",
        "2.   Balancing the Dataset\n",
        "2.   Filter using bass band filters for increasing SNR\n",
        "3.   Feature extraction\n",
        "4.    Normalization\n",
        "5.   SVM Vs. KNN for classification\n",
        "6.   testing & validation using K-fold\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EEgD_sZulOK",
        "colab_type": "text"
      },
      "source": [
        "# Importing and installing needed libraries & setting google drive folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGTY25vIunZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa, librosa.display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s66fpNfPMtl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlkRpmxPMxCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= pd.read_csv('/content/drive/My Drive/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJudKmEfNjY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting it into binary lables\n",
        "df[\"OUTPUT_LABEL\"] = df.y == 1\n",
        "df[\"OUTPUT_LABEL\"] = df[\"OUTPUT_LABEL\"].astype(int)\n",
        "df.pop('y')\n",
        "df.drop(df.columns[0], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0hYp8OGN6OA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dd278ee-ee77-486a-b03b-d1d965146d72"
      },
      "source": [
        "def calc_prevalence(y_actual):\n",
        "    # this function calculates the prevalence of the positive class (label = 1)\n",
        "    return sum(y_actual) / len(y_actual)\n",
        "\n",
        "\n",
        "print(\n",
        "    \"prevalence of the positive class: %.3f\"\n",
        "    % calc_prevalence(df[\"OUTPUT_LABEL\"].values)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prevalence of the positive class: 0.200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x5nEYagu6x6",
        "colab_type": "text"
      },
      "source": [
        "#Filtering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgNKktfQK0iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcde81XfwLPn",
        "colab_type": "text"
      },
      "source": [
        "#Features Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-R-jgPLzwNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Statistical\n",
        "def statisticalMean(signal):\n",
        "  return abs(np.mean(signal))\n",
        "\n",
        "def statisticalSTD(signal):\n",
        "  return np.std(signal)\n",
        "\n",
        "def statisticalSkewness(signal):\n",
        "  return signal.skew()\n",
        "\n",
        "def statisticalKurtosis(signal):\n",
        "  return signal.kurtosis()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFfgVWzhzzZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Spectral\n",
        "def averageEnergy(signal):\n",
        "  summation = 0\n",
        "  for i in range(len(signal)):\n",
        "    summation = summation + ((signal[i])**2)\n",
        "  avg_energy = summation/ (len(signal))\n",
        "  return avg_energy\n",
        "\n",
        "def spectralCentroid(signal):\n",
        "  #It is calculated as the weighted mean of the frequencies present in the signal, \n",
        "  #determined using a Fourier transform, with their magnitudes as the weights.\n",
        "  n = len(signal)\n",
        "  timestep = 1/178\n",
        "  spectrum = abs(np.fft.rfft(signal)) #using FT to compute frequcies present in the signal\n",
        "  normalized_spectrum = spectrum / sum(spectrum)  # like a probability mass function\n",
        "  normalized_frequencies = np.linspace(0, 1, len(spectrum))\n",
        "  spectral_centroid = sum(normalized_frequencies * normalized_spectrum)\n",
        "  freq = np.fft.rfftfreq(n, d=timestep) #get frequncies\n",
        "  freq_max= freq.max() \n",
        "  # Spectral centroid is calculated as a ratio.  Multiply by your maximum frequency bin to get real frequency.\n",
        "  spectral_centroid= freq_max * spectral_centroid\n",
        "  return spectral_centroid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otX1lF5rwS9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def signalFilter(data, fs):\n",
        "  delta = butter_bandpass_filter(data, 0.5, 4, fs, order=4)\n",
        "  theta = butter_bandpass_filter(data, 4, 8, fs, order=4)\n",
        "  alpha = butter_bandpass_filter(data, 8, 12, fs, order=4)\n",
        "  beta = butter_bandpass_filter(data, 12, 25, fs, order=4)\n",
        "  return delta,theta,alpha,beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0AMzwARue7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_extract(dataframe):\n",
        "  \n",
        "  df_features= dataframe.drop(['OUTPUT_LABEL'], axis=1)\n",
        "  df_features= butter_bandpass_filter(df_features, lowcut=0.5, highcut=25, fs=178, order=4)\n",
        "  df_features= df_features.T\n",
        "  df_frame= pd.DataFrame(df_features)\n",
        "  e_dataframe= pd.DataFrame()\n",
        "  \n",
        "  std_l=[]\n",
        "  skew_l= []\n",
        "  kurtosis_l=[]\n",
        "  spC_l=[]\n",
        "  deltaList= []\n",
        "  thetaList= []\n",
        "  alphaList= []\n",
        "  betaList= []\n",
        "\n",
        "  \n",
        "  for column in df_frame:\n",
        "\n",
        "    delta,theta,alpha,beta = signalFilter(df_frame[column], 178)\n",
        "    deltaList.append(averageEnergy(delta))\n",
        "    thetaList.append(averageEnergy(theta))\n",
        "    alphaList.append(averageEnergy(alpha))\n",
        "    betaList.append(averageEnergy(beta))\n",
        "\n",
        "    stat_std= statisticalSTD(df_frame[column])\n",
        "    std_l.append(stat_std)\n",
        "\n",
        "    stat_skew= statisticalSkewness(df_frame[column])\n",
        "    skew_l.append(stat_skew)\n",
        "\n",
        "    stat_kurtosis= statisticalKurtosis(df_frame[column])\n",
        "    kurtosis_l.append(stat_kurtosis)\n",
        "\n",
        "    spec_cetroid= spectralCentroid(df_frame[column])\n",
        "    spC_l.append(spec_cetroid)\n",
        "\n",
        "  e_dataframe['Standard Deviation']= std_l\n",
        "  e_dataframe['Skewness']= skew_l\n",
        "  e_dataframe['Kurtosis']= kurtosis_l\n",
        "  e_dataframe['Spectral Centroid']= spC_l\n",
        "  e_dataframe['delta'] = deltaList\n",
        "  e_dataframe['theta'] = thetaList\n",
        "  e_dataframe['alpha'] = alphaList\n",
        "  e_dataframe['beta'] = betaList\n",
        "  \n",
        "  return e_dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC56By2UwaXA",
        "colab_type": "text"
      },
      "source": [
        "#Normalization(Feature Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkERQ3vEMi44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def normalizeData(dataFrame):\n",
        "  minRange = 0\n",
        "  maxRange = 100\n",
        "  scaler = MinMaxScaler(feature_range=(minRange, maxRange), copy=True)\n",
        "  df = pd.DataFrame(scaler.fit_transform(dataFrame),columns=dataFrame.columns, index=dataFrame.index) \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb1qmSd6AJ1S",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH8MYqiIMmD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features= filter_extract(df)\n",
        "result= normalizeData(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GzaI3hPXBL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result['Label']= df['OUTPUT_LABEL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOm9CsjMygu",
        "colab_type": "text"
      },
      "source": [
        "# SVM Vs. KNN Classification\n",
        "using proposed algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dpz7dIrR27x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7e9b5518-3be1-45e2-dee6-66cff1c4ae71"
      },
      "source": [
        "#svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   \n",
        "#print(accuracy_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[1818   26]\n",
            " [  56  400]]\n",
            "new Matrix\n",
            "[[1832   18]\n",
            " [  46  404]]\n",
            "new Matrix\n",
            "[[1813   19]\n",
            " [  37  431]]\n",
            "new Matrix\n",
            "[[1815   24]\n",
            " [  48  413]]\n",
            "new Matrix\n",
            "[[1813   22]\n",
            " [  50  415]]\n",
            "the total confusion matrix is [[9091.  109.]\n",
            " [ 237. 2063.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve7wlWfiB-Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Results of SVM \n",
        "Accuracy= 0.96\n",
        "Specificity= 0.98\n",
        "Sensitivity= 0.89"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV7D6gA8WxZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fb2b5f78-8a8b-4940-bdf8-3902bdb3abc0"
      },
      "source": [
        "#KNN\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "  \n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "      \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        "  \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "  # Split train-test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  # Train the model\n",
        "  model = classifier.fit(X_train, y_train)\n",
        "  y_predict = classifier.predict(X_test)\n",
        "  print(\"new Matrix\")\n",
        "  print(confusion_matrix(y_test,y_predict))\n",
        "  # Append to accuracy_model the accuracy of the model\n",
        "  cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "  accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[1823   21]\n",
            " [  32  424]]\n",
            "new Matrix\n",
            "[[1829   21]\n",
            " [  27  423]]\n",
            "new Matrix\n",
            "[[1805   27]\n",
            " [  28  440]]\n",
            "new Matrix\n",
            "[[1817   22]\n",
            " [  38  423]]\n",
            "new Matrix\n",
            "[[1808   27]\n",
            " [  40  425]]\n",
            "the total confusion matrix is [[9082.  118.]\n",
            " [ 165. 2135.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNRfe4RnCR7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Results of KNN \n",
        "Accuracy= 0.97\n",
        "Specificity= 0.98\n",
        "Sensitivity= 0.92"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}