{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MIT_final",
      "provenance": [],
      "collapsed_sections": [
        "2exTMbtHHbBC",
        "ajctInSNQuF7",
        "CGI03SiufHww",
        "fLfZxE-qgdw5",
        "cB_imXEeluxV",
        "Cqdp8Lsgt2XW",
        "mVrPfiyyg3bv",
        "1bTKItpPknhc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVC6M7JDxoh_",
        "colab_type": "text"
      },
      "source": [
        "# Seizure Predicition Procedure\n",
        "1.   Combine all EEG signal channels using Averaging\n",
        "2.   Filter using bass band filters for increasing SNR\n",
        "3.   Feature extraction\n",
        "4.   Normalization\n",
        "5.   Balancing the dataset\n",
        "6.   SVM Vs. KNN for classification\n",
        "7. Testing & validation using k-fold\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_cCBShMyVOS",
        "colab_type": "text"
      },
      "source": [
        "# Importing and installing needed libraries & setting google drive folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf4UH6G4LWGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import abs, sum, linspace\n",
        "from numpy.fft import rfft\n",
        "import librosa, librosa.display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYUOX4DTwyxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7e43d96d-d629-4df9-90ad-e4ce629744ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnJazEgdhN9q",
        "colab_type": "text"
      },
      "source": [
        "#Ready surrogate channel( CSV files containing averaged output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwsPAspgO2od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patient1_3Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_3Surrogate_df.csv')\n",
        "patient1_3Surrogate_np= patient1_3Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient1_4Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_4Surrogate_df.csv')\n",
        "patient1_4Surrogate_np= patient1_4Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient1_15Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_15Surrogate_df.csv')\n",
        "patient1_15Surrogate_np= patient1_15Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient1_16Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_16Surrogate_df.csv')\n",
        "patient1_16Surrogate_np= patient1_16Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient1_18Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_18Surrogate_df.csv')\n",
        "patient1_18Surrogate_np= patient1_18Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient1_21Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient1_21Surrogate_df.csv')\n",
        "patient1_21Surrogate_np= patient1_21Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient3_2Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient3_2Surrogate_df.csv')\n",
        "patient3_2Surrogate_np= patient3_2Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient5_6Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient5_6Surrogate_df.csv')\n",
        "patient5_6Surrogate_np= patient5_6Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient5_13Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient5_13Surrogate_df.csv')\n",
        "patient5_13Surrogate_np= patient5_13Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient5_16Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient5_16Surrogate_df.csv')\n",
        "patient5_16Surrogate_np= patient5_16Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient12_09Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient12_09Surrogate_df.csv')\n",
        "patient12_09Surrogate_np= patient12_09Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient18_29Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient18_29Surrogate_df.csv')\n",
        "patient18_29Surrogate_np= patient18_29Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient18_31Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient18_31Surrogate_df.csv')\n",
        "patient18_31Surrogate_np= patient18_31Surrogate_df['0'].to_numpy()\n",
        "\n",
        "patient24_04Surrogate_df= pd.read_csv('/content/drive/My Drive/Graduationnn/trial/patient24_04Surrogate_df.csv')\n",
        "patient24_04Surrogate_np= patient24_04Surrogate_df['0'][210:].to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rusptpKIN-JL",
        "colab_type": "text"
      },
      "source": [
        "#Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKMFH_dANt1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wx42v8bNw9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def signalFilter(data, fs):\n",
        "  delta = butter_bandpass_filter(data, 0.5, 4, fs, order=4)\n",
        "  theta = butter_bandpass_filter(data, 4, 8, fs, order=4)\n",
        "  alpha = butter_bandpass_filter(data, 8, 12, fs, order=4)\n",
        "  beta = butter_bandpass_filter(data, 12, 25, fs, order=4)\n",
        "  return delta,theta,alpha,beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9i5rzBAjS-6",
        "colab_type": "text"
      },
      "source": [
        "#Featurs Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cheQbOhpjR7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Statistical\n",
        "def statisticalMean(signal):\n",
        "  return abs(np.mean(signal))\n",
        "\n",
        "def statisticalSTD(signal):\n",
        "  return np.std(signal)\n",
        "\n",
        "def statisticalSkewness(signal):\n",
        "  dataframe = pd.DataFrame(signal)\n",
        "  return dataframe.skew()[0]\n",
        "\n",
        "def statisticalKurtosis(signal):\n",
        "  dataframe = pd.DataFrame(signal)\n",
        "  return dataframe.kurtosis()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu3knQ7lG3Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Spectral\n",
        "def spectralCentroid(signal):\n",
        "  #It is calculated as the weighted mean of the frequencies present in the signal, \n",
        "  #determined using a Fourier transform, with their magnitudes as the weights.\n",
        "  n = len(signal)\n",
        "  timestep = 1/256\n",
        "  spectrum = abs(np.fft.rfft(signal)) #using FT to compute frequcies present in the signal\n",
        "  normalized_spectrum = spectrum / sum(spectrum)  # like a probability mass function\n",
        "  normalized_frequencies = np.linspace(0, 1, len(spectrum))\n",
        "  spectral_centroid = sum(normalized_frequencies * normalized_spectrum)\n",
        "  freq = np.fft.rfftfreq(n, d=timestep) #get frequncies\n",
        "  freq_max= freq.max() \n",
        "  # Spectral centroid is calculated as a ratio.  Multiply by your maximum frequency bin to get real frequency.\n",
        "  spectral_centroid= freq_max * spectral_centroid\n",
        "  return spectral_centroid\n",
        "\n",
        "def averageEnergy(signal):\n",
        "  summation = 0\n",
        "  for i in range(len(signal)):\n",
        "    summation = summation + ((signal[i])**2)\n",
        "  avg_energy = summation/ (len(signal))\n",
        "  return avg_energy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9fGO0DE08J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def divide_and_filter(signal,frame_length,hop_length):\n",
        "  \n",
        "  signal= butter_bandpass_filter(signal, lowcut=0.5, highcut=25, fs=256, order=4)\n",
        "  frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length)\n",
        "  \n",
        "  e_dataframe= pd.DataFrame()\n",
        "  std_l=[]\n",
        "  skew_l=[]\n",
        "  kurtosis_l=[]\n",
        "  spC_l=[]\n",
        "  deltaList= []\n",
        "  thetaList= []\n",
        "  alphaList= []\n",
        "  betaList= []\n",
        "  \n",
        "  for frame in frames.T:\n",
        "    delta,theta,alpha,beta = signalFilter(frame, 256)\n",
        "    deltaList.append(averageEnergy(delta))\n",
        "    thetaList.append(averageEnergy(theta))\n",
        "    alphaList.append(averageEnergy(alpha))\n",
        "    betaList.append(averageEnergy(beta))\n",
        "    \n",
        "    stat_std= statisticalSTD(frame)\n",
        "    std_l.append(stat_std)\n",
        "\n",
        "    stat_skew= statisticalSkewness(frame)\n",
        "    skew_l.append(stat_skew)\n",
        "\n",
        "    stat_kurtosis= statisticalKurtosis(frame)\n",
        "    kurtosis_l.append(stat_kurtosis)\n",
        "    \n",
        "    spec_cetroid= spectralCentroid(frame)\n",
        "    spC_l.append(spec_cetroid)\n",
        "\n",
        "  e_dataframe['Standard Deviation']= std_l\n",
        "  e_dataframe['Skewness']= skew_l\n",
        "  e_dataframe['Kurtosis']= kurtosis_l\n",
        "  e_dataframe['Spectral Centroid']= spC_l\n",
        "  e_dataframe['delta'] = deltaList\n",
        "  e_dataframe['theta'] = thetaList\n",
        "  e_dataframe['alpha'] = alphaList\n",
        "  e_dataframe['beta'] = betaList\n",
        "\n",
        "  return e_dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_gQndhOUiE",
        "colab_type": "text"
      },
      "source": [
        "#Normalization (feature Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d75s2LAOTn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def normalizeData(dataFrame):\n",
        "  minRange = 0\n",
        "  maxRange = 100\n",
        "  scaler = MinMaxScaler(feature_range=(minRange, maxRange), copy=True)\n",
        "  df = pd.DataFrame(scaler.fit_transform(dataFrame),columns=dataFrame.columns, index=dataFrame.index) \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cb71GoOxFv",
        "colab_type": "text"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB8W2AD19fHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#patient1_3h\n",
        "patient1_3h_ex= divide_and_filter(patient1_3Surrogate_np,2560,2560)\n",
        "patient1_3h_ex_norm= normalizeData(patient1_3h_ex)\n",
        "\n",
        "#patient1_4h\n",
        "patient1_4h_ex= divide_and_filter(patient1_4Surrogate_np,2560,2560)\n",
        "patient1_4h_ex_norm= normalizeData(patient1_4h_ex)\n",
        "\n",
        "#patient1_15h\n",
        "patient1_15h_ex= divide_and_filter(patient1_15Surrogate_np,2560,2560)\n",
        "patient1_15h_ex_norm= normalizeData(patient1_15h_ex)\n",
        "\n",
        "#patient1_16h\n",
        "patient1_16h_ex= divide_and_filter(patient1_16Surrogate_np,2560,2560)\n",
        "patient1_16h_ex_norm= normalizeData(patient1_16h_ex)\n",
        "\n",
        "#patient1_18h\n",
        "patient1_18h_ex= divide_and_filter(patient1_18Surrogate_np,2560,2560)\n",
        "patient1_18h_ex_norm= normalizeData(patient1_18h_ex)\n",
        "\n",
        "#patient1_21h\n",
        "patient1_21h_ex= divide_and_filter(patient1_21Surrogate_np,2560,2560)\n",
        "patient1_21h_ex_norm= normalizeData(patient1_21h_ex)\n",
        "\n",
        "#patient3_2h\n",
        "patient3_2h_ex= divide_and_filter(patient3_2Surrogate_np,2560,2560)\n",
        "patient3_2h_ex_norm= normalizeData(patient3_2h_ex)\n",
        "#patient 12_9h\n",
        "patient12_9h_ex= divide_and_filter(patient12_09Surrogate_np,2560,2560)\n",
        "patient12_9h_ex_norm= normalizeData(patient12_9h_ex)\n",
        "\n",
        "#patient5\n",
        "patient5_6h_ex= divide_and_filter(patient5_6Surrogate_np,2560,2560)\n",
        "patient5_6h_ex_norm= normalizeData(patient5_6h_ex)\n",
        "\n",
        "patient5_13h_ex= divide_and_filter(patient5_13Surrogate_np,2560,2560)\n",
        "patient5_13h_ex_norm= normalizeData(patient5_13h_ex)\n",
        "\n",
        "patient5_16h_ex= divide_and_filter(patient5_16Surrogate_np,2560,2560)\n",
        "patient5_16h_ex_norm= normalizeData(patient5_16h_ex)\n",
        "\n",
        "#patient 18_29h\n",
        "patient18_29h_ex= divide_and_filter(patient18_29Surrogate_np,2560,2560)\n",
        "patient18_29h_ex_norm= normalizeData(patient18_29h_ex)\n",
        "\n",
        "#patient 18_31h\n",
        "patient18_31h_ex= divide_and_filter(patient18_31Surrogate_np,2560,2560)\n",
        "patient18_31h_ex_norm= normalizeData(patient18_31h_ex)\n",
        "\n",
        "#patient 24_4h\n",
        "patient24_4h_ex= divide_and_filter(patient24_04Surrogate_np,2560,2560)\n",
        "patient24_4h_ex_norm= normalizeData(patient24_4h_ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXmH1UF6-skn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patient1_3h_ex_norm[\"Label\"] = 0\n",
        "patient1_3h_ex_norm.iloc[300:303]['Label']=1\n",
        "\n",
        "patient1_4h_ex_norm[\"Label\"] = 0\n",
        "patient1_4h_ex_norm.iloc[146:151]['Label']=1\n",
        "\n",
        "patient1_15h_ex_norm[\"Label\"] = 0\n",
        "patient1_15h_ex_norm.iloc[173:177]['Label']=1\n",
        "\n",
        "patient1_16h_ex_norm[\"Label\"] = 0\n",
        "patient1_16h_ex_norm.iloc[100:106]['Label']=1\n",
        "\n",
        "patient1_18h_ex_norm[\"Label\"] = 0\n",
        "patient1_18h_ex_norm.iloc[172:181]['Label']=1\n",
        "\n",
        "patient1_21h_ex_norm[\"Label\"] = 0\n",
        "patient1_21h_ex_norm.iloc[33:42]['Label']=1\n",
        "\n",
        "patient3_2h_ex_norm[\"Label\"] = 0\n",
        "patient3_2h_ex_norm.iloc[73:80]['Label']=1\n",
        "\n",
        "patient12_9h_ex_norm[\"Label\"] = 0\n",
        "patient12_9h_ex_norm.iloc[308:311]['Label']=1\n",
        "\n",
        "patient5_6h_ex_norm[\"Label\"] = 0\n",
        "patient5_6h_ex_norm.iloc[46:54]['Label']=1\n",
        "\n",
        "patient5_13h_ex_norm[\"Label\"] = 0\n",
        "patient5_13h_ex_norm.iloc[111:120]['Label']=1\n",
        "\n",
        "patient5_16h_ex_norm[\"Label\"] = 0\n",
        "patient5_16h_ex_norm.iloc[235:241]['Label']=1\n",
        "\n",
        "patient18_29h_ex_norm[\"Label\"] = 0\n",
        "patient18_29h_ex_norm.iloc[349:353]['Label']=1\n",
        "\n",
        "patient18_31h_ex_norm[\"Label\"] = 0\n",
        "patient18_31h_ex_norm.iloc[208:213]['Label']=1\n",
        "\n",
        "patient24_4h_ex_norm[\"Label\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwYzCdvGizIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00cd3341-a486-4850-d10f-4454f83262ad"
      },
      "source": [
        "frames= [patient1_3h_ex_norm[280:320], patient1_4h_ex_norm[130:170],patient1_15h_ex_norm[150:190],patient1_16h_ex_norm[80:120],patient1_18h_ex_norm[155:195],\n",
        "         patient1_21h_ex_norm[15:55], patient3_2h_ex_norm[55:95],patient12_9h_ex_norm[280:320], patient5_6h_ex_norm[25:65], patient5_13h_ex_norm[95:135], \n",
        "         patient5_16h_ex_norm[215:255],patient18_29h_ex_norm[313:353], patient18_31h_ex_norm[176:216], patient24_4h_ex_norm[0:20]]\n",
        "result = pd.concat(frames)\n",
        "result=result.reset_index()\n",
        "result=result.drop(columns='index')\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(540, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW2mVp1wIykL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb81c733-71d6-4844-baaf-ddfaf50971bf"
      },
      "source": [
        "result.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Standard Deviation</th>\n",
              "      <th>Skewness</th>\n",
              "      <th>Kurtosis</th>\n",
              "      <th>Spectral Centroid</th>\n",
              "      <th>delta</th>\n",
              "      <th>theta</th>\n",
              "      <th>alpha</th>\n",
              "      <th>beta</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.984302</td>\n",
              "      <td>51.877290</td>\n",
              "      <td>19.518346</td>\n",
              "      <td>34.460581</td>\n",
              "      <td>0.919281</td>\n",
              "      <td>4.593203</td>\n",
              "      <td>18.575051</td>\n",
              "      <td>11.474303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.379791</td>\n",
              "      <td>46.531777</td>\n",
              "      <td>8.659403</td>\n",
              "      <td>25.335442</td>\n",
              "      <td>1.943445</td>\n",
              "      <td>4.248461</td>\n",
              "      <td>28.115566</td>\n",
              "      <td>39.160667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.030767</td>\n",
              "      <td>50.193374</td>\n",
              "      <td>38.259478</td>\n",
              "      <td>32.286168</td>\n",
              "      <td>3.619233</td>\n",
              "      <td>4.276488</td>\n",
              "      <td>21.241020</td>\n",
              "      <td>25.410534</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.729856</td>\n",
              "      <td>41.554274</td>\n",
              "      <td>8.201615</td>\n",
              "      <td>26.018449</td>\n",
              "      <td>0.509283</td>\n",
              "      <td>2.907127</td>\n",
              "      <td>16.505304</td>\n",
              "      <td>16.966855</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.971547</td>\n",
              "      <td>53.989292</td>\n",
              "      <td>26.815773</td>\n",
              "      <td>10.311566</td>\n",
              "      <td>4.158961</td>\n",
              "      <td>2.801256</td>\n",
              "      <td>16.613062</td>\n",
              "      <td>31.270486</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Standard Deviation   Skewness   Kurtosis  ...      alpha       beta  Label\n",
              "0            5.984302  51.877290  19.518346  ...  18.575051  11.474303      0\n",
              "1            9.379791  46.531777   8.659403  ...  28.115566  39.160667      0\n",
              "2           13.030767  50.193374  38.259478  ...  21.241020  25.410534      0\n",
              "3            3.729856  41.554274   8.201615  ...  16.505304  16.966855      0\n",
              "4           13.971547  53.989292  26.815773  ...  16.613062  31.270486      0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbmZsK7v1_Bu",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine Vs. KNN Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Vi8pa-xVuOV",
        "colab_type": "text"
      },
      "source": [
        "#All patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndA3oTIlfjJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4f8da769-9cb4-4cd7-9f64-bb64bd70380b"
      },
      "source": [
        "#Trial 1: Band bass filter & time and spectral old features\n",
        "#SVM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   \n",
        "#print(accuracy_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[589   0]\n",
            " [  3   5]]\n",
            "new Matrix\n",
            "[[568   0]\n",
            " [ 13  15]]\n",
            "new Matrix\n",
            "[[570   2]\n",
            " [  2  22]]\n",
            "new Matrix\n",
            "[[584   3]\n",
            " [  3   6]]\n",
            "new Matrix\n",
            "[[576  11]\n",
            " [  3   6]]\n",
            "the total confusion matrix is [[2887.   16.]\n",
            " [  24.   54.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVknuXkzUYmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results of svm \n",
        "specificity= 0.99\n",
        "sensitivity= 0.70\n",
        "accuracy= 0.98"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq2F6rkilQ9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d76ccae6-21d2-4d6a-942d-983056cadd2d"
      },
      "source": [
        "#Trial 4: Band bass filter & all features without mean and average energy.\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[589   0]\n",
            " [  2   6]]\n",
            "new Matrix\n",
            "[[568   0]\n",
            " [  6  22]]\n",
            "new Matrix\n",
            "[[570   2]\n",
            " [  8  16]]\n",
            "new Matrix\n",
            "[[579   8]\n",
            " [  2   7]]\n",
            "new Matrix\n",
            "[[581   6]\n",
            " [  1   8]]\n",
            "the total confusion matrix is [[2887.   16.]\n",
            " [  19.   59.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIkhnjbnTMaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results of svm \n",
        "specificity= 0.99\n",
        "sensitivity= 0.76\n",
        "accuracy= 0.988"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82hMdK0sklwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ae5233ba-e574-4137-9d0e-d7ff0bbe8b6b"
      },
      "source": [
        "#Trial 4: Band bass filter & all features without mean and average energy.\n",
        "#SVM\n",
        "# resampling: downsizing >> ratio: 0.14\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[95  1]\n",
            " [ 2 10]]\n",
            "new Matrix\n",
            "[[91  2]\n",
            " [ 2 13]]\n",
            "new Matrix\n",
            "[[84  5]\n",
            " [ 2 17]]\n",
            "new Matrix\n",
            "[[83  2]\n",
            " [ 7 16]]\n",
            "new Matrix\n",
            "[[98  1]\n",
            " [ 1  8]]\n",
            "the total confusion matrix is [[451.  11.]\n",
            " [ 14.  64.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nWRTlWVuVZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f19ef1fb-c3e8-499f-f268-2af600a8c0ef"
      },
      "source": [
        "#Trial 4: Band bass filter & all features without mean and average energy.\n",
        "#knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=5,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_predict = classifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   \n",
        "print(accuracy_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[588   1]\n",
            " [  3   5]]\n",
            "new Matrix\n",
            "[[568   0]\n",
            " [  6  22]]\n",
            "new Matrix\n",
            "[[570   2]\n",
            " [ 10  14]]\n",
            "new Matrix\n",
            "[[582   5]\n",
            " [  2   7]]\n",
            "new Matrix\n",
            "[[581   6]\n",
            " [  1   8]]\n",
            "the total confusion matrix is [[2889.   14.]\n",
            " [  22.   56.]]\n",
            "[99.32998324958125, 98.99328859060402, 97.98657718120806, 98.8255033557047, 98.8255033557047]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlKrDQ-MTq-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results of KNN \n",
        "specificity= 0.99\n",
        "sensitivity= 0.72\n",
        "accuracy= 0.987"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoxTzITbVkdG",
        "colab_type": "text"
      },
      "source": [
        "#Single Patient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBM9eXIDVo4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3512c3e-b94a-4580-f486-068956111f40"
      },
      "source": [
        "frames_1= [patient1_3h_ex_norm[280:320], patient1_4h_ex_norm[130:170],patient1_15h_ex_norm[150:190],patient1_16h_ex_norm[80:120],patient1_18h_ex_norm[155:195],\n",
        "         patient1_21h_ex_norm[15:55]]\n",
        "result = pd.concat(frames_1)\n",
        "result=result.reset_index()\n",
        "result=result.drop(columns='index')\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilJmaDDVqQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5999996e-f362-4522-bf79-6aec84f18dce"
      },
      "source": [
        "#Trial 4: Band bass filter & all features without mean and average energy.\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=3,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[417   0]\n",
            " [  0   3]]\n",
            "new Matrix\n",
            "[[401   4]\n",
            " [  2  13]]\n",
            "new Matrix\n",
            "[[402   0]\n",
            " [  3  15]]\n",
            "the total confusion matrix is [[1220.    4.]\n",
            " [   5.   31.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwB7XR2VWlhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results of SVM for 1 patient\n",
        "specificity= 0.98\n",
        "sensitivity= 0.86\n",
        "accuracy= 0.98"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6v6GolzpxgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7277f633-5c95-4679-aa5e-29205dbc187c"
      },
      "source": [
        "#Trial 4: Band bass filter & all features without mean and average energy.\n",
        "#SVM\n",
        "#down sampling\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "svclassifier = SVC(kernel='linear',C=1)\n",
        "\n",
        "X = result.drop(columns=['Label'],axis=1)\n",
        "y = result['Label']\n",
        "\n",
        "# KFold Cross Validation approach\n",
        "kf = KFold(n_splits=3,shuffle=False)\n",
        "kf.split(X)    \n",
        "     \n",
        "# Initialize the accuracy of the models to blank list. The accuracy of each model will be appended to this list\n",
        "accuracy_model = []\n",
        " \n",
        "# Iterate over each train-test split\n",
        "cm_holder=[]\n",
        "total=np.empty([2, 2])\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split train-test\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Train the model\n",
        "    model = svclassifier.fit(X_train, y_train)\n",
        "    y_predict = svclassifier.predict(X_test)\n",
        "    print(\"new Matrix\")\n",
        "    print(confusion_matrix(y_test,y_predict))\n",
        "    # Append to accuracy_model the accuracy of the model\n",
        "    cm_holder.append(confusion_matrix(y_test, y_predict))\n",
        "    accuracy_model.append(accuracy_score(y_test, model.predict(X_test), normalize=True)*100)\n",
        "for i in range(len(cm_holder)):\n",
        "  total= total+ cm_holder[i]\n",
        "print(\"the total confusion matrix is\", total)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new Matrix\n",
            "[[72  0]\n",
            " [ 2  6]]\n",
            "new Matrix\n",
            "[[64  6]\n",
            " [ 0 10]]\n",
            "new Matrix\n",
            "[[62  0]\n",
            " [ 1 17]]\n",
            "the total confusion matrix is [[198.   6.]\n",
            " [  3.  33.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQH0ThSOqZsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results of SVM for 1 patient\n",
        "specificity= 0.98\n",
        "sensitivity= 0.91\n",
        "accuracy= 0.98"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}